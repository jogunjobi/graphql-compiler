{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import namedtuple\n",
    "from itertools import chain, repeat\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    AbstractSet, Any, Callable, Collection, Dict, Generic, Iterable, Mapping, NamedTuple, \n",
    "    Optional, Tuple, TypeVar, Union\n",
    ")\n",
    "\n",
    "from funcy.py3 import chunks\n",
    "from graphql import GraphQLList, GraphQLString\n",
    "from graphql_compiler.compiler.blocks import (\n",
    "    Backtrack, CoerceType, ConstructResult, Filter, GlobalOperationsStart, MarkLocation, \n",
    "    QueryRoot, Traverse\n",
    ")\n",
    "from graphql_compiler.compiler.compiler_entities import BasicBlock, Expression\n",
    "from graphql_compiler.compiler.expressions import (\n",
    "    BinaryComposition, ContextField, Literal, LocalField, OutputContextField, Variable\n",
    ")\n",
    "from graphql_compiler.compiler.compiler_frontend import IrAndMetadata, graphql_to_ir\n",
    "from graphql_compiler.compiler.helpers import Location, get_only_element_from_collection\n",
    "from graphql_compiler.schema import GraphQLDate, GraphQLDateTime, GraphQLDecimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterInfo = namedtuple(\n",
    "    'FilterInfo',\n",
    "    ('field_name', 'op_name', 'value'),\n",
    ")\n",
    "DataToken = TypeVar('DataToken')\n",
    "\n",
    "\n",
    "class LineageToken(NamedTuple):\n",
    "    token: DataToken\n",
    "    lineage_by_location: Dict[Location, DataToken]\n",
    "\n",
    "        \n",
    "def make_empty_lineage_token(token: DataToken):\n",
    "    return LineageToken(token=token, lineage_by_location=dict())\n",
    "        \n",
    "\n",
    "class InterpreterAdapter(Generic[DataToken], metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def get_tokens_of_type(\n",
    "        self,\n",
    "        type_name: str, \n",
    "        filter_hints: Collection[FilterInfo], \n",
    "        required_connection_hints: AbstractSet[str]\n",
    "    ) -> Iterable[DataToken]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def project_property(\n",
    "        self,\n",
    "        tokens: Iterable[DataToken], \n",
    "        field_name: str\n",
    "    ) -> Iterable[Any]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def project_neighbors(\n",
    "        self,\n",
    "        tokens: Iterable[LineageToken], \n",
    "        direction: str,\n",
    "        edge_name: str, \n",
    "        neighbor_type_hint: Optional[str],\n",
    "        filter_hints: Collection[FilterInfo],\n",
    "        required_connection_hints: AbstractSet[str]\n",
    "    ) -> Iterable[Tuple[LineageToken, DataToken]]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def coerce_to_type(\n",
    "        self,\n",
    "        tokens: Iterable[LineageToken], \n",
    "        type_name: str\n",
    "    ) -> Iterable[LineageToken]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `funcy.chunks` instead of `itertools.tee` to be able to control the \"lag\" across\n",
    "the different uses of a given iterable. If we used `itertools.tee`, we'd likely end up exhausting\n",
    "each iterable before continuing on to the next one, which is explicitly listed as a misuse\n",
    "of `itertools.tee` in its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_local_field(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    expression: LocalField,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Any]:\n",
    "    field_name = expression.field_name\n",
    "    tokens = (\n",
    "        lineage_token.token\n",
    "        for lineage_token in lineages\n",
    "    )\n",
    "    return adapter.project_property(tokens, field_name)\n",
    "\n",
    "\n",
    "def _handle_context_field(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    expression: Union[ContextField, OutputContextField],\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Any]:\n",
    "    if isinstance(expression, OutputContextField):\n",
    "        lineages = _print_tap('output context field', lineages)\n",
    "    \n",
    "    location = expression.location.at_vertex()\n",
    "    field_name = expression.location.field\n",
    "    tokens = (\n",
    "        lineage_token.lineage_by_location[location]\n",
    "        for lineage_token in lineages\n",
    "    )\n",
    "    return adapter.project_property(tokens, field_name)\n",
    "\n",
    "\n",
    "def _handle_variable(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    expression: Variable,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Any]:\n",
    "    variable_value = query_arguments[expression.variable_name[1:]]\n",
    "    return repeat(variable_value)\n",
    "\n",
    "\n",
    "def _handle_binary_composition(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    expression: BinaryComposition,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Any]:\n",
    "    for lineages_chunk in chunks(1000, lineages):\n",
    "        left_values = _handle_expression(adapter, query_arguments, expression.left, lineages_chunk)\n",
    "        right_values = _handle_expression(adapter, query_arguments, expression.right, lineages_chunk)\n",
    "        \n",
    "        yield from (\n",
    "            _apply_operator(expression.operator, left_value, right_value)\n",
    "            for left_value, right_value in zip(left_values, right_values)\n",
    "        )\n",
    "\n",
    "        \n",
    "def _apply_operator(operator: str, left_value: Any, right_value: Any) -> Any:\n",
    "    if operator == '=':\n",
    "        return left_value == right_value\n",
    "    elif operator == 'contains':\n",
    "        return right_value in left_value\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_expression(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    expression: Expression,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Any]:\n",
    "    type_to_handler = {\n",
    "        BinaryComposition: _handle_binary_composition,\n",
    "        ContextField: _handle_context_field,\n",
    "        OutputContextField: _handle_context_field,\n",
    "        LocalField: _handle_local_field,\n",
    "        Variable: _handle_variable,\n",
    "    }\n",
    "    expression_type = type(expression)\n",
    "    return type_to_handler[expression_type](adapter, query_arguments, expression, lineages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zip_dict_iterables(dict_of_iterables: Dict[str, Iterable[Any]]) -> Iterable[Dict[str, Any]]:\n",
    "    \"\"\"Zip a dict of iterables into an iterable of dicts containing the values of the iterables.\"\"\"\n",
    "    key_value_iterables = [\n",
    "        zip(repeat(key), values)\n",
    "        for key, values in dict_of_iterables.items()\n",
    "    ]\n",
    "    return (\n",
    "        dict(set_of_values)\n",
    "        for set_of_values in zip(*key_value_iterables)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_construct_result(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: ConstructResult,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[Dict[str, Any]]:\n",
    "    output_fields = block.fields\n",
    "    \n",
    "    for lineages_chunk in chunks(1000, lineages):        \n",
    "        output_name_to_expression_values = {\n",
    "            output_name: _handle_expression(adapter, query_arguments, expression, lineages_chunk)\n",
    "            for output_name, expression in output_fields.items()\n",
    "        }\n",
    "        yield from _zip_dict_iterables(output_name_to_expression_values)\n",
    "    \n",
    "\n",
    "def _handle_filter(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: Filter,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    predicate = block.predicate\n",
    "    for lineages_chunk in chunks(1000, lineages):\n",
    "        yield from (\n",
    "            lineage\n",
    "            for lineage, predicate_value in zip(\n",
    "                lineages_chunk,\n",
    "                _handle_expression(adapter, query_arguments, predicate, lineages_chunk)\n",
    "            )\n",
    "            if predicate_value\n",
    "        )\n",
    "    \n",
    "    \n",
    "def _handle_coerce_type(\n",
    "    adapter: InterpreterAdapter[DataToken],\n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: CoerceType,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    coercion_type = get_only_element_of_collection(block.target_class)\n",
    "    return adapter.coerce_to_type(lineages, coercion_type)\n",
    "    \n",
    "\n",
    "def _handle_mark_location(\n",
    "    adapter: InterpreterAdapter[DataToken],\n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: MarkLocation,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    current_location = block.location\n",
    "    for lineage_token in lineages:\n",
    "        lineage_by_location = dict(lineage_token.lineage_by_location)\n",
    "        lineage_by_location[current_location] = lineage_token.token\n",
    "        yield LineageToken(\n",
    "            token=lineage_token.token,\n",
    "            lineage_by_location=lineage_by_location,\n",
    "        )\n",
    "        \n",
    "\n",
    "def _handle_backtrack(\n",
    "    adapter: InterpreterAdapter[DataToken],\n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: Backtrack,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    backtrack_location = block.location\n",
    "    for lineage_token in lineages:\n",
    "        yield LineageToken(\n",
    "            token=lineage_token.lineage_by_location[backtrack_location],\n",
    "            lineage_by_location=lineage_token.lineage_by_location,\n",
    "        )\n",
    "        \n",
    "        \n",
    "def _handle_traverse(\n",
    "    adapter: InterpreterAdapter[DataToken],\n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: Traverse,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    if block.optional:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    neighbor_batches = adapter.project_neighbors(\n",
    "        lineages, block.direction, block.edge_name, None, [], set())\n",
    "    for lineage, neighbor_token in neighbor_batches:\n",
    "        yield LineageToken(token=neighbor_token, lineage_by_location=lineage.lineage_by_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_block(\n",
    "    adapter: InterpreterAdapter[DataToken],\n",
    "    query_arguments: Dict[str, Any],\n",
    "    block: BasicBlock,\n",
    "    lineages: Iterable[LineageToken],\n",
    ") -> Iterable[LineageToken]:\n",
    "    no_op_types = (GlobalOperationsStart,)\n",
    "    if isinstance(block, no_op_types):\n",
    "        return lineages\n",
    "    \n",
    "    lineages = _print_tap('pre: ' + str(block), lineages)\n",
    "    \n",
    "    handler_functions = {        \n",
    "        CoerceType: _handle_coerce_type,\n",
    "        Filter: _handle_filter,\n",
    "        MarkLocation: _handle_mark_location,\n",
    "        Traverse: _handle_traverse,\n",
    "        Backtrack: _handle_backtrack,\n",
    "    }\n",
    "    return handler_functions[type(block)](adapter, query_arguments, block, lineages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_tap(info: str, lineages: Iterable[LineageToken]) -> Iterable[LineageToken]:\n",
    "    return lineages\n",
    "#     print('\\n')\n",
    "#     unique_id = hash(info)\n",
    "#     print(unique_id, info)\n",
    "#     for lineage_chunk in chunks(100, lineages):\n",
    "#         for lineage in lineage_chunk:\n",
    "#             pprint((unique_id, lineage))\n",
    "#             yield lineage\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_ir(\n",
    "    adapter: InterpreterAdapter[DataToken], \n",
    "    ir_and_metadata: IrAndMetadata, \n",
    "    query_arguments: Dict[str, Any]\n",
    ") -> Iterable[Dict[str, Any]]:\n",
    "    ir_blocks = ir_and_metadata.ir_blocks\n",
    "    query_metadata_table = ir_and_metadata.query_metadata_table\n",
    "    \n",
    "    if not ir_blocks:\n",
    "        raise AssertionError()\n",
    "        \n",
    "    first_block = ir_blocks[0]\n",
    "    if not isinstance(first_block, QueryRoot):\n",
    "        raise AssertionError()\n",
    "        \n",
    "    last_block = ir_blocks[-1]\n",
    "    if not isinstance(last_block, ConstructResult):\n",
    "        raise AssertionError()\n",
    "        \n",
    "    middle_blocks = ir_blocks[1:-1]\n",
    "        \n",
    "    start_class = get_only_element_from_collection(first_block.start_class)\n",
    "    \n",
    "    current_lineages = (\n",
    "        make_empty_lineage_token(token)\n",
    "        for token in adapter.get_tokens_of_type(start_class, [], set())\n",
    "    )\n",
    "    \n",
    "    current_lineages = _print_tap('starting lineages', current_lineages)\n",
    "    \n",
    "    for block in middle_blocks:\n",
    "        current_lineages = _handle_block(adapter, query_arguments, block, current_lineages)\n",
    "        \n",
    "    current_lineages = _print_tap('ending lineages', current_lineages)\n",
    "        \n",
    "    return _handle_construct_result(\n",
    "        adapter, query_arguments, last_block, current_lineages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = {\n",
    "    'Animal': [\n",
    "        {'name': 'Scooby Doo', 'uuid': '1001'},\n",
    "        {'name': 'Hedwig', 'uuid': '1002'},\n",
    "        {'name': 'Beethoven', 'uuid': '1003'},\n",
    "        {'name': 'Pongo', 'uuid': '1004'},\n",
    "        {'name': 'Perdy', 'uuid': '1005'},\n",
    "        {'name': 'Dipstick', 'uuid': '1006'},\n",
    "        {'name': 'Dottie', 'uuid': '1007'},\n",
    "        {'name': 'Domino', 'uuid': '1008'},\n",
    "        {'name': 'Little Dipper', 'uuid': '1009'},\n",
    "        {'name': 'Oddball', 'uuid': '1010'},\n",
    "    ],\n",
    "}\n",
    "edges = {\n",
    "    'Animal_ParentOf': [\n",
    "        ('1004', '1006'),\n",
    "        ('1005', '1006'),\n",
    "        ('1006', '1008'),\n",
    "        ('1006', '1009'),\n",
    "        ('1006', '1010'),\n",
    "        ('1007', '1008'),\n",
    "        ('1007', '1009'),\n",
    "        ('1007', '1010'),\n",
    "    ],\n",
    "}\n",
    "\n",
    "vertices_by_uuid = {\n",
    "    vertex['uuid']: vertex\n",
    "    for vertex in chain.from_iterable(vertices.values())\n",
    "}\n",
    "\n",
    "\n",
    "class InMemoryAdapter(InterpreterAdapter[dict]):\n",
    "    def get_tokens_of_type(\n",
    "        self,\n",
    "        type_name: str, \n",
    "        filter_hints: Collection[FilterInfo], \n",
    "        required_connection_hints: AbstractSet[str]\n",
    "    ) -> Iterable[dict]:\n",
    "        return vertices[type_name]\n",
    "\n",
    "    def project_property(\n",
    "        self,\n",
    "        tokens: Iterable[dict], \n",
    "        field_name: str\n",
    "    ) -> Iterable[Any]:\n",
    "        return (\n",
    "            token[field_name]\n",
    "            for token in tokens\n",
    "        )\n",
    "\n",
    "    def project_neighbors(\n",
    "        self,\n",
    "        tokens: Iterable[LineageToken], \n",
    "        direction: str,\n",
    "        edge_name: str, \n",
    "        neighbor_type_hint: Optional[str],\n",
    "        filter_hints: Collection[FilterInfo],\n",
    "        required_connection_hints: AbstractSet[str]\n",
    "    ) -> Iterable[Tuple[LineageToken, DataToken]]:\n",
    "        edge_info = edges[edge_name]\n",
    "        for lineage in tokens:\n",
    "            uuid = lineage.token['uuid']\n",
    "            if direction == 'out':\n",
    "                yield from (\n",
    "                    (lineage, vertices_by_uuid[destination_uuid])\n",
    "                    for source_uuid, destination_uuid in edge_info\n",
    "                    if source_uuid == uuid\n",
    "                )\n",
    "            elif direction == 'in':\n",
    "                yield from (\n",
    "                    (lineage, vertices_by_uuid[source_uuid])\n",
    "                    for source_uuid, destination_uuid in edge_info\n",
    "                    if destination_uuid == uuid\n",
    "                )\n",
    "            else:\n",
    "                raise AssertionError()\n",
    "\n",
    "    def coerce_to_type(\n",
    "        self,\n",
    "        tokens: Iterable[LineageToken], \n",
    "        type_name: str\n",
    "    ) -> Iterable[LineageToken]:\n",
    "        # no-op\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = Location(('Animal',))\n",
    "blocks = [\n",
    "    QueryRoot({'Animal'}),\n",
    "    MarkLocation(base_location),\n",
    "    GlobalOperationsStart(),\n",
    "    ConstructResult({\n",
    "        'animal_name': OutputContextField(\n",
    "            base_location.navigate_to_field('name'), GraphQLString)\n",
    "    }),\n",
    "]\n",
    "query_arguments = {}\n",
    "input_metadata = {}\n",
    "output_metadata = {}\n",
    "query_metadata_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = Location(('Animal',))\n",
    "child_location = base_location.navigate_to_subpath('out_Animal_ParentOf')\n",
    "\n",
    "blocks = [\n",
    "    QueryRoot({'Animal'}),\n",
    "    MarkLocation(base_location),\n",
    "    Traverse('out', 'Animal_ParentOf'),\n",
    "    MarkLocation(child_location),\n",
    "    Backtrack(base_location),\n",
    "    GlobalOperationsStart(),\n",
    "    ConstructResult({\n",
    "        'parent_name': OutputContextField(\n",
    "            base_location.navigate_to_field('name'), GraphQLString),\n",
    "        'child_name': OutputContextField(\n",
    "            child_location.navigate_to_field('name'), GraphQLString),\n",
    "    }),\n",
    "]\n",
    "query_arguments = {}\n",
    "input_metadata = {}\n",
    "output_metadata = {}\n",
    "query_metadata_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = Location(('Animal',))\n",
    "child_location = base_location.navigate_to_subpath('out_Animal_ParentOf')\n",
    "\n",
    "blocks = [\n",
    "    QueryRoot({'Animal'}),\n",
    "    MarkLocation(base_location),\n",
    "    Traverse('out', 'Animal_ParentOf'),\n",
    "    Filter(\n",
    "        BinaryComposition(\n",
    "            u'=',\n",
    "            LocalField('name', GraphQLString),\n",
    "            Variable('$child', GraphQLString),\n",
    "        )\n",
    "    ),\n",
    "    MarkLocation(child_location),\n",
    "    Backtrack(base_location),\n",
    "    GlobalOperationsStart(),\n",
    "    ConstructResult({\n",
    "        'parent_name': OutputContextField(\n",
    "            base_location.navigate_to_field('name'), GraphQLString),\n",
    "        'child_name': OutputContextField(\n",
    "            child_location.navigate_to_field('name'), GraphQLString),\n",
    "    }),\n",
    "]\n",
    "query_arguments = {\n",
    "    'child': 'Domino',\n",
    "}\n",
    "input_metadata = {\n",
    "    'child': GraphQLString\n",
    "}\n",
    "output_metadata = {}\n",
    "query_metadata_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_location = Location(('Animal',))\n",
    "child_location = base_location.navigate_to_subpath('out_Animal_ParentOf')\n",
    "\n",
    "blocks = [\n",
    "    QueryRoot({'Animal'}),\n",
    "    MarkLocation(base_location),\n",
    "    Traverse('out', 'Animal_ParentOf'),\n",
    "    Filter(\n",
    "        BinaryComposition(\n",
    "            u'contains',\n",
    "            Variable('$child_names', GraphQLString),\n",
    "            LocalField('name', GraphQLString),\n",
    "        )\n",
    "    ),\n",
    "    MarkLocation(child_location),\n",
    "    Backtrack(base_location),\n",
    "    GlobalOperationsStart(),\n",
    "    ConstructResult({\n",
    "        'parent_name': OutputContextField(\n",
    "            base_location.navigate_to_field('name'), GraphQLString),\n",
    "        'child_name': OutputContextField(\n",
    "            child_location.navigate_to_field('name'), GraphQLString),\n",
    "    }),\n",
    "]\n",
    "query_arguments = {\n",
    "    'child_names': ['Domino', 'Dipstick', 'Oddball'],\n",
    "}\n",
    "input_metadata = {\n",
    "    'child_names': GraphQLList(GraphQLString)\n",
    "}\n",
    "output_metadata = {}\n",
    "query_metadata_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parent_name': 'Pongo', 'child_name': 'Dipstick'},\n",
       " {'parent_name': 'Perdy', 'child_name': 'Dipstick'},\n",
       " {'parent_name': 'Dipstick', 'child_name': 'Domino'},\n",
       " {'parent_name': 'Dipstick', 'child_name': 'Oddball'},\n",
       " {'parent_name': 'Dottie', 'child_name': 'Domino'},\n",
       " {'parent_name': 'Dottie', 'child_name': 'Oddball'}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_and_metadata = IrAndMetadata(\n",
    "    blocks, input_metadata, output_metadata, query_metadata_table\n",
    ")\n",
    "result = list(interpret_ir(InMemoryAdapter(), ir_and_metadata, query_arguments))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
